{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OPTML.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "78639c31b6fd41dcbe17d2073cb85b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_284f305bd0344e30860ab8fd8d06ac67",
              "IPY_MODEL_0176ff64f6c84ebc8e735e89aaf54c8f",
              "IPY_MODEL_0e79565d403e42a8bfe4b5ee094aa082"
            ],
            "layout": "IPY_MODEL_70475afc20034d0c9c617b44777ceb7e"
          }
        },
        "284f305bd0344e30860ab8fd8d06ac67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89562f153aac4d2a8b9726bb0e5d9030",
            "placeholder": "​",
            "style": "IPY_MODEL_8c0b8e460e2a4e0bad3fd0f637886395",
            "value": ""
          }
        },
        "0176ff64f6c84ebc8e735e89aaf54c8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ec4e712cff04802af5c6da187426ed9",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_590d681d93814432a7cc166ea9c8d984",
            "value": 170498071
          }
        },
        "0e79565d403e42a8bfe4b5ee094aa082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54125956ff414fd785788464a119e50d",
            "placeholder": "​",
            "style": "IPY_MODEL_2f09b834d1d646fbb0ca2bc34c21e890",
            "value": " 170499072/? [00:03&lt;00:00, 75224040.56it/s]"
          }
        },
        "70475afc20034d0c9c617b44777ceb7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89562f153aac4d2a8b9726bb0e5d9030": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c0b8e460e2a4e0bad3fd0f637886395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ec4e712cff04802af5c6da187426ed9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "590d681d93814432a7cc166ea9c8d984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54125956ff414fd785788464a119e50d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f09b834d1d646fbb0ca2bc34c21e890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aPzqnIz-T95u"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.parallel\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set variables\n",
        "\n",
        "#training options\n",
        "batch_size = 128\n",
        "lr_val = 0.1\n",
        "start_epoch = 1\n",
        "lr_decay = 0.1\n",
        "optimizer_val = 'sgd' #adam | lbfgs\n",
        "weight_decay = 0.0005\n",
        "momentum = 0.9\n",
        "epochs = 2\n",
        "save = 'trained_nets'\n",
        "save_epoch = 10\n",
        "ngpu = 1\n",
        "rand_seed = 0\n",
        "resume_model = ''\n",
        "resume_opt = ''\n",
        "save_folder = ''\n",
        "\n",
        "#model parameters\n",
        "model = 'resnet18'\n",
        "loss_name = 'crossentropy'\n",
        "raw_data = False\n",
        "noaug = False\n",
        "label_corrupt_prob = 0.0\n",
        "trainloader_val = ''\n",
        "testloader_val = ''\n",
        "idx = 0"
      ],
      "metadata": {
        "id": "Pr17sTxJUDYO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "# print('Current devices: ' + str(torch.cuda.current_device()))\n",
        "# print('Device count: ' + str(torch.cuda.device_count()))"
      ],
      "metadata": {
        "id": "pMcTERNYUHCU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def name_save_folder():\n",
        "    save_folder = 'model' + '_' + str(optimizer_val) + '_lr=' + str(lr_val)\n",
        "    if lr_decay != 0.1:\n",
        "        save_folder += '_lr_decay=' + str(lr_decay)\n",
        "    save_folder += '_bs=' + str(batch_size)\n",
        "    save_folder += '_wd=' + str(weight_decay)\n",
        "    save_folder += '_mom=' + str(momentum)\n",
        "    save_folder += '_save_epoch=' + str(save_epoch)\n",
        "    if loss_name != 'crossentropy':\n",
        "        save_folder += '_loss=' + str(loss_name)\n",
        "    if noaug:\n",
        "        save_folder += '_noaug'\n",
        "    if raw_data:\n",
        "        save_folder += '_rawdata'\n",
        "    if label_corrupt_prob > 0:\n",
        "        save_folder += '_randlabel=' + str(label_corrupt_prob)\n",
        "    if ngpu > 1:\n",
        "        save_folder += '_ngpu=' + str(ngpu)\n",
        "    if idx:\n",
        "        save_folder += '_idx=' + str(idx)\n",
        "\n",
        "    return save_folder"
      ],
      "metadata": {
        "id": "AtBq5thGVwRG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_loaders(trainloader, testloader):\n",
        "    if trainloader and testloader:\n",
        "        assert os.path.exists(trainloader), 'trainloader does not exist'\n",
        "        assert os.path.exists(testloader), 'testloader does not exist'\n",
        "        trainloader = torch.load(trainloader)\n",
        "        testloader = torch.load(testloader)\n",
        "        return trainloader, testloader\n",
        "\n",
        "    normalize = transforms.Normalize(mean=[x/255.0 for x in [125.3, 123.0, 113.9]],\n",
        "                                     std=[x/255.0 for x in [63.0, 62.1, 66.7]])\n",
        "\n",
        "    if raw_data:\n",
        "        transform_train = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "    else:\n",
        "        if not noaug:\n",
        "            # with data augmentation\n",
        "            transform_train = transforms.Compose([\n",
        "                transforms.RandomCrop(32, padding=4),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])\n",
        "        else:\n",
        "            # no data agumentation\n",
        "            transform_train = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ])\n",
        "\n",
        "\n",
        "    kwargs = {'num_workers': 2, 'pin_memory': True} if ngpu else {}\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True,\n",
        "                                            transform=transform_train)\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True,\n",
        "                                           transform=transform_test)\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                              shuffle=True, **kwargs)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                             shuffle=False, **kwargs)\n",
        "\n",
        "    return trainloader, testloader"
      ],
      "metadata": {
        "id": "ATjEXsU-YllX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#basicblock and resnet class\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1   = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2   = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1  = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1    = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ImageNet models\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2,2,2,2])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Vh3saaDpa__G"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# map between model name and function\n",
        "models = {\n",
        "    'resnet18'              : ResNet18\n",
        "}\n"
      ],
      "metadata": {
        "id": "x_HKn81FbSF-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load(model_name, model_file=None, data_parallel=False):\n",
        "    net = models[model_name]()\n",
        "    if data_parallel: # the model is saved in data paralle mode\n",
        "        net = torch.nn.DataParallel(net)\n",
        "\n",
        "    if model_file:\n",
        "        assert os.path.exists(model_file), model_file + \" does not exist.\"\n",
        "        stored = torch.load(model_file, map_location=lambda storage, loc: storage)\n",
        "        if 'state_dict' in stored.keys():\n",
        "            net.load_state_dict(stored['state_dict'])\n",
        "        else:\n",
        "            net.load_state_dict(stored)\n",
        "\n",
        "    if data_parallel: # convert the model back to the single GPU version\n",
        "        net = net.module\n",
        "\n",
        "    net.eval()\n",
        "    return net"
      ],
      "metadata": {
        "id": "ERa0lTljbWgh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize params; only for first training\n",
        "\n",
        "def init_params(net):\n",
        "    for m in net.modules():\n",
        "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "            init.kaiming_normal_(m.weight, mode='fan_in')\n",
        "            if m.bias is not None:\n",
        "                init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            init.constant_(m.weight, 1)\n",
        "            init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            init.normal_(m.weight, std=1e-3)\n",
        "            if m.bias is not None:\n",
        "                init.constant_(m.bias, 0)"
      ],
      "metadata": {
        "id": "5m1EOEMfbk3a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def closure():\n",
        "#     optimizer.zero_grad()\n",
        "#     loss.backward()\n",
        "#     return loss\n"
      ],
      "metadata": {
        "id": "yF8IfEmmZ_vf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "def train(trainloader, net, criterion, optimizer, use_cuda=True):\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    if isinstance(criterion, nn.CrossEntropyLoss):\n",
        "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "            batch_size = inputs.size(0)\n",
        "            total += batch_size\n",
        "            if use_cuda:\n",
        "                inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            inputs, targets = Variable(inputs), Variable(targets)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            if optimizer_val=='sgd' or optimizer_val=='adam':\n",
        "              optimizer.step()\n",
        "            else:\n",
        "              optimizer.step(loss)\n",
        "            train_loss += loss.item()*batch_size\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += predicted.eq(targets.data).cpu().sum().item()\n",
        "\n",
        "    elif isinstance(criterion, nn.MSELoss):\n",
        "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "            batch_size = inputs.size(0)\n",
        "            total += batch_size\n",
        "\n",
        "            one_hot_targets = torch.FloatTensor(batch_size, 10).zero_()\n",
        "            one_hot_targets = one_hot_targets.scatter_(1, targets.view(batch_size, 1), 1.0)\n",
        "            one_hot_targets = one_hot_targets.float()\n",
        "            if use_cuda:\n",
        "                inputs, one_hot_targets = inputs.cuda(), one_hot_targets.cuda()\n",
        "            inputs, one_hot_targets = Variable(inputs), Variable(one_hot_targets)\n",
        "            outputs = F.softmax(net(inputs))\n",
        "            loss = criterion(outputs, one_hot_targets)\n",
        "            loss.backward()\n",
        "            if optimizer_val=='sgd' or optimizer_val=='sgd':\n",
        "              optimizer.step()\n",
        "            else:\n",
        "              optimizer.step(loss)\n",
        "            train_loss += loss.item()*batch_size\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += predicted.cpu().eq(targets).cpu().sum().item()\n",
        "\n",
        "    return train_loss/total, 100 - 100.*correct/total\n"
      ],
      "metadata": {
        "id": "roR8NY8rdmeT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(testloader, net, criterion, use_cuda=True):\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    if isinstance(criterion, nn.CrossEntropyLoss):\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            batch_size = inputs.size(0)\n",
        "            total += batch_size\n",
        "\n",
        "            if use_cuda:\n",
        "                inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            inputs, targets = Variable(inputs), Variable(targets)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss += loss.item()*batch_size\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += predicted.eq(targets.data).cpu().sum().item()\n",
        "\n",
        "    elif isinstance(criterion, nn.MSELoss):\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            batch_size = inputs.size(0)\n",
        "            total += batch_size\n",
        "\n",
        "            one_hot_targets = torch.FloatTensor(batch_size, 10).zero_()\n",
        "            one_hot_targets = one_hot_targets.scatter_(1, targets.view(batch_size, 1), 1.0)\n",
        "            one_hot_targets = one_hot_targets.float()\n",
        "            if use_cuda:\n",
        "                inputs, one_hot_targets = inputs.cuda(), one_hot_targets.cuda()\n",
        "            inputs, one_hot_targets = Variable(inputs), Variable(one_hot_targets)\n",
        "            outputs = F.softmax(net(inputs))\n",
        "            loss = criterion(outputs, one_hot_targets)\n",
        "            test_loss += loss.item()*batch_size\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += predicted.cpu().eq(targets).cpu().sum().item()\n",
        "\n",
        "    return test_loss/total, 100 - 100.*correct/total"
      ],
      "metadata": {
        "id": "qbywkJM8doQX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(lr_val, start_epoch):\n",
        "  random.seed(rand_seed)\n",
        "  np.random.seed(rand_seed)\n",
        "  torch.manual_seed(rand_seed)\n",
        "\n",
        "  if use_cuda:\n",
        "    torch.cuda.manual_seed_all(rand_seed)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "  \n",
        "  if not os.path.isdir(save):\n",
        "    os.mkdir(save)\n",
        "\n",
        "  save_folder = name_save_folder()\n",
        "\n",
        "  if not os.path.exists('trained_nets/' + save_folder):\n",
        "    os.makedirs('trained_nets/' + save_folder)\n",
        "\n",
        "  f = open('trained_nets/' + save_folder + '/log.out', 'a')\n",
        "\n",
        "  trainloader, testloader = get_data_loaders(trainloader_val, testloader_val)\n",
        "\n",
        "\n",
        "  if label_corrupt_prob and not resume_model:\n",
        "        torch.save(trainloader, 'trained_nets/' + save_folder + '/trainloader.dat')\n",
        "        torch.save(testloader, 'trained_nets/' + save_folder + '/testloader.dat')\n",
        "\n",
        "  \n",
        "\n",
        "  # Model\n",
        "  if resume_model:\n",
        "      # Load checkpoint.\n",
        "      print('==> Resuming from checkpoint..')\n",
        "      checkpoint = torch.load(resume_model)\n",
        "      if optimizer_val=='sgd':  #check if its first time; since first time we use sgd\n",
        "        net = load(model)\n",
        "      else:\n",
        "        net = pytorch_model\n",
        "      net.load_state_dict(checkpoint['state_dict'])\n",
        "      start_epoch = checkpoint['epoch'] + 1\n",
        "  else:\n",
        "      if optimizer_val=='sgd':  #check if its first time; since first time we use sgd\n",
        "        net = load(model)\n",
        "      else:\n",
        "        net = pytorch_model\n",
        "      # print(net)\n",
        "      # init_params(net)\n",
        "\n",
        "  \n",
        "  if ngpu > 1:\n",
        "        net = torch.nn.DataParallel(net)\n",
        "\n",
        "  \n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "  if loss_name == 'crossentropy':\n",
        "        criterion = nn.MSELoss()\n",
        "\n",
        "\n",
        "  if use_cuda:\n",
        "        net.cuda()\n",
        "        criterion = criterion.cuda()\n",
        "\n",
        "\n",
        "  # Optimizer\n",
        "  if optimizer_val == 'sgd':\n",
        "      optimizer = optim.SGD(net.parameters(), lr=lr_val, momentum=momentum, weight_decay=weight_decay, nesterov=True)\n",
        "  elif optimizer_val=='adam':\n",
        "      optimizer = optim.Adam(net.parameters(), lr=lr_val, weight_decay=weight_decay)\n",
        "  else:\n",
        "      optimizer = optim.LBFGS(net.parameters(), lr=lr_val)\n",
        "\n",
        "\n",
        "  \n",
        "  if resume_opt:\n",
        "    checkpoint_opt = torch.load(resume_opt)\n",
        "    optimizer.load_state_dict(checkpoint_opt['optimizer'])\n",
        "\n",
        "  \n",
        "\n",
        "  # record the performance of initial model\n",
        "  if not resume_model:\n",
        "      train_loss, train_err = test(trainloader, net, criterion, use_cuda)\n",
        "      test_loss, test_err = test(testloader, net, criterion, use_cuda)\n",
        "      status = 'e: %d loss: %.5f train_err: %.3f test_top1: %.3f test_loss %.5f \\n' % (0, train_loss, train_err, test_err, test_loss)\n",
        "      print(status)\n",
        "      f.write(status)\n",
        "\n",
        "      state = {\n",
        "          'acc': 100 - test_err,\n",
        "          'epoch': 0,\n",
        "          'state_dict': net.module.state_dict() if ngpu > 1 else net.state_dict()\n",
        "      }\n",
        "      opt_state = {\n",
        "          'optimizer': optimizer.state_dict()\n",
        "      }\n",
        "      torch.save(state, 'trained_nets/' + save_folder + '/model_0.t7')\n",
        "      torch.save(opt_state, 'trained_nets/' + save_folder + '/opt_state_0.t7')\n",
        "\n",
        "\n",
        "  \n",
        "  for epoch in range(start_epoch, epochs + 1):\n",
        "        loss, train_err = train(trainloader, net, criterion, optimizer, use_cuda)\n",
        "        test_loss, test_err = test(testloader, net, criterion, use_cuda)\n",
        "\n",
        "        status = 'e: %d loss: %.5f train_err: %.3f test_top1: %.3f test_loss %.5f \\n' % (epoch, loss, train_err, test_err, test_loss)\n",
        "        print(status)\n",
        "        f.write(status)\n",
        "\n",
        "        # Save checkpoint.\n",
        "        acc = 100 - test_err\n",
        "        if epoch == 1 or epoch % save_epoch == 0 or epoch == 150:\n",
        "            state = {\n",
        "                'acc': acc,\n",
        "                'epoch': epoch,\n",
        "                'state_dict': net.module.state_dict() if ngpu > 1 else net.state_dict(),\n",
        "            }\n",
        "            opt_state = {\n",
        "                'optimizer': optimizer.state_dict()\n",
        "            }\n",
        "            torch.save(state, 'trained_nets/' + save_folder + '/model_' + str(epoch) + '.t7')\n",
        "            torch.save(opt_state, 'trained_nets/' + save_folder + '/opt_state_' + str(epoch) + '.t7')\n",
        "\n",
        "            \n",
        "\n",
        "        if int(epoch) == 150 or int(epoch) == 225 or int(epoch) == 275:\n",
        "            lr_val *= lr_decay\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] *= lr_decay\n",
        "\n",
        "  torch.save(net.state_dict(),'model_'+optimizer_val+\"_\" '.pt')\n",
        "\n",
        "  f.close()"
      ],
      "metadata": {
        "id": "G1UiKXuUUJy7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main(lr_val, start_epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412,
          "referenced_widgets": [
            "78639c31b6fd41dcbe17d2073cb85b2d",
            "284f305bd0344e30860ab8fd8d06ac67",
            "0176ff64f6c84ebc8e735e89aaf54c8f",
            "0e79565d403e42a8bfe4b5ee094aa082",
            "70475afc20034d0c9c617b44777ceb7e",
            "89562f153aac4d2a8b9726bb0e5d9030",
            "8c0b8e460e2a4e0bad3fd0f637886395",
            "1ec4e712cff04802af5c6da187426ed9",
            "590d681d93814432a7cc166ea9c8d984",
            "54125956ff414fd785788464a119e50d",
            "2f09b834d1d646fbb0ca2bc34c21e890"
          ]
        },
        "id": "NfAWcZYEUqG2",
        "outputId": "2d62304f-f1bf-4371-8470-f5100d01e565"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78639c31b6fd41dcbe17d2073cb85b2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-eeae2474441d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-9eec3a19c066>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(lr_val, start_epoch)\u001b[0m\n\u001b[1;32m     82\u001b[0m   \u001b[0;31m# record the performance of initial model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresume_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m       \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m       \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m       \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'e: %d loss: %.5f train_err: %.3f test_top1: %.3f test_loss %.5f \\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-e7d363eae43a>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(testloader, net, criterion, use_cuda)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-414ffbc51dda>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-414ffbc51dda>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    442\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    443\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 444\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def setmodel():\n",
        "  pytorch_model =  ResNet18()\n",
        "\n",
        "  #/content/model_sgd_.pt\n",
        "  pytorch_model.load_state_dict(torch.load('/content/model_'+optimizer_val+'_.pt'))\n",
        "  pytorch_model.eval()\n",
        "\n",
        "  return pytorch_model\n",
        "\n"
      ],
      "metadata": {
        "id": "bQX5_ruVUx47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_val = 'adam'\n",
        "pytorch_model = setmodel()\n",
        "main(lr_val, start_epoch)"
      ],
      "metadata": {
        "id": "bXihymYJg8Il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_val = 'LBFGS'\n",
        "pytorch_model = setmodel()\n",
        "main(lr_val, start_epoch)"
      ],
      "metadata": {
        "id": "auKmbX8f3VtS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}