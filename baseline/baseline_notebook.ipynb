{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEq_NKmEW9nW"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.autograd import Variable\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "def get_data_loaders():\n",
        "    normalize = transforms.Normalize(mean=[x/255.0 for x in [125.3, 123.0, 113.9]],\n",
        "                                     std=[x/255.0 for x in [63.0, 62.1, 66.7]])\n",
        "\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ])\n",
        "\n",
        "\n",
        "    kwargs = {'num_workers': 2, 'pin_memory': True}\n",
        "\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True,\n",
        "                                            transform=transform_train)\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True,\n",
        "                                        transform=transform_test)\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                            shuffle=True, **kwargs)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                            shuffle=False, **kwargs)\n",
        "\n",
        "    return trainloader, testloader\n",
        "\n",
        "#basicblock and resnet class\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1   = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2   = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=100):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1  = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1    = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "# ImageNet models\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2,2,2,2], 10)\n",
        "\n",
        "cfg = {\n",
        "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "}\n",
        "\n",
        "\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self, vgg_name, num):\n",
        "        super(VGG, self).__init__()\n",
        "        self.input_size = 32\n",
        "        self.features = self._make_layers(cfg[vgg_name])\n",
        "        self.n_maps = cfg[vgg_name][-2]\n",
        "        self.fc = self._make_fc_layers()\n",
        "        self.classifier = nn.Linear(self.n_maps, num)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "    def _make_fc_layers(self):\n",
        "        layers = []\n",
        "        layers += [nn.Linear(self.n_maps*self.input_size*self.input_size, self.n_maps),\n",
        "                   nn.BatchNorm1d(self.n_maps),\n",
        "                   nn.ReLU(inplace=True)]\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _make_layers(self, cfg):\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for x in cfg:\n",
        "            if x == 'M':\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)]\n",
        "                self.input_size = self.input_size // 2\n",
        "            else:\n",
        "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
        "                           nn.BatchNorm2d(x),\n",
        "                           nn.ReLU(inplace=True)]\n",
        "                in_channels = x\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "def VGG16():\n",
        "    return VGG('VGG16', 10)\n",
        "\n",
        "\n",
        "# map between model name and function\n",
        "models = {\n",
        "    'resnet18': ResNet18,\n",
        "    'vgg16': VGG16,\n",
        "}\n",
        "\n",
        "def load(model_name):\n",
        "    net = models[model_name]()\n",
        "    net.eval()\n",
        "    return net\n",
        "\n",
        "#initialize params\n",
        "def init_params(net):\n",
        "    for m in net.modules():\n",
        "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "            init.kaiming_normal_(m.weight, mode='fan_in')\n",
        "            if m.bias is not None:\n",
        "                init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            init.constant_(m.weight, 1)\n",
        "            init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            init.normal_(m.weight, std=1e-3)\n",
        "            if m.bias is not None:\n",
        "                init.constant_(m.bias, 0)\n",
        "\n",
        "# Training\n",
        "def train(trainloader, net, criterion, optimizer, use_cuda=True):\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    if isinstance(criterion, nn.CrossEntropyLoss):\n",
        "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "            batch_size = inputs.size(0)\n",
        "            total += batch_size\n",
        "            if use_cuda:\n",
        "                inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            inputs, targets = Variable(inputs), Variable(targets)\n",
        "                     \n",
        "            if optimizer_val=='sgd' or optimizer_val=='adam':\n",
        "              outputs = net(inputs)\n",
        "              loss = criterion(outputs, targets)\n",
        "              loss.backward()\n",
        "              optimizer.step()     \n",
        "\n",
        "            train_loss += loss.item()*batch_size\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += predicted.eq(targets.data).cpu().sum().item()\n",
        "\n",
        "    return train_loss/total, 100 - 100.*correct/total,  100.*correct/total\n",
        "\n",
        "def test(testloader, net, criterion, use_cuda=True):\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    if isinstance(criterion, nn.CrossEntropyLoss):\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            batch_size = inputs.size(0)\n",
        "            total += batch_size\n",
        "\n",
        "            if use_cuda:\n",
        "                inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            inputs, targets = Variable(inputs), Variable(targets)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss += loss.item()*batch_size\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += predicted.eq(targets.data).cpu().sum().item()\n",
        "\n",
        "    return test_loss/total, 100 - 100.*correct/total,  100.*correct/total\n",
        "\n",
        "\n",
        "def main(model_name, rand_seed, optimizer_val):\n",
        "    random.seed(rand_seed)\n",
        "    np.random.seed(rand_seed)\n",
        "    torch.manual_seed(rand_seed)\n",
        "    if use_cuda:\n",
        "        torch.cuda.manual_seed_all(rand_seed)\n",
        "        cudnn.benchmark = True\n",
        "\n",
        "    trainloader, testloader = get_data_loaders()\n",
        "    net = ResNet18() if model_name == 'ResNet18' else VGG16()\n",
        "    init_params(net)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if use_cuda:\n",
        "        net.cuda()\n",
        "        criterion = criterion.cuda()\n",
        "\n",
        "    if optimizer_val == 'sgd':\n",
        "        lr_val = 0.1\n",
        "        optimizer = optim.SGD(net.parameters(), lr=lr_val, momentum=momentum, weight_decay=weight_decay, nesterov=True)\n",
        "    elif optimizer_val == 'adam':\n",
        "        lr_val = 0.001\n",
        "        optimizer = optim.Adam(net.parameters(), lr=lr_val, weight_decay=weight_decay)\n",
        "   \n",
        "    train_losses = np.zeros(epochs)\n",
        "    train_accuracy = np.zeros(epochs)\n",
        "    val_losses = np.zeros(epochs)\n",
        "    val_accuracy = np.zeros(epochs)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        loss, train_err, train_acc = train(trainloader, net, criterion, optimizer, use_cuda)\n",
        "        train_losses[epoch] = loss\n",
        "        train_accuracy[epoch] = train_acc\n",
        "        test_loss, test_err, test_acc = test(testloader, net, criterion, use_cuda)\n",
        "        val_losses[epoch] = test_loss\n",
        "        val_accuracy[epoch] = test_acc\n",
        "        status = 'epoch: %d loss: %.5f train_err: %.3f train_acc: %.3f test_top1: %.3f test_loss %.5f test_acc: %.3f\\n' % (epoch, loss, train_err, train_acc, test_err, test_loss, test_acc)\n",
        "        print(status)\n",
        "       \n",
        "        if int(epoch) == 0.3*epochs or int(epoch) == 0.6*epochs or int(epoch) == 0.8*epochs:\n",
        "            lr_val *= lr_decay\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] *= lr_decay\n",
        "\n",
        "    return train_losses, train_accuracy, val_losses, val_accuracy, net\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "start_epoch = 1\n",
        "lr_decay = 0.2\n",
        "weight_decay = 0.0005\n",
        "momentum = 0.9\n",
        "epochs = 200\n",
        "loss_name = 'crossentropy'\n",
        "\n",
        "# models = ['ResNet18', 'VGG16']\n",
        "# seeds = [0, 1, 2]\n",
        "# opts = ['sgd', 'adam']\n",
        "\n",
        "models = ['ResNet18']\n",
        "seeds = [0]\n",
        "opts = ['sgd']"
      ],
      "metadata": {
        "id": "ilV12w8TMwFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name in models:\n",
        "    for rand_seed in seeds:\n",
        "        for optimizer_val in opts:\n",
        "            train_losses, train_accuracy, val_losses, val_accuracy, net = main(model_name, rand_seed, optimizer_val)\n",
        "\n",
        "            torch.save(net.state_dict(), f'{optimizer_val}_baseline_{model_name}_seed{rand_seed}.pt')\n",
        "            with open(f'{optimizer_val}_baseline_{model_name}_seed{rand_seed}.npy', 'wb') as numpy_file:\n",
        "                np.save(numpy_file, train_losses)\n",
        "                np.save(numpy_file, train_accuracy)\n",
        "                np.save(numpy_file, val_losses)\n",
        "                np.save(numpy_file, val_accuracy)"
      ],
      "metadata": {
        "id": "MtzHykmAXN5j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}